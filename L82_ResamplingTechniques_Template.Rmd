---
title: "Resampling Techniques"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this tutorial different resampling methods are presented: hold-out method, k-fold cross validation and leave-one-out cross validation. We start with bias-variance tradeoff and will analyse different techniques in a real example and classify wines with random forest.

# Bias-Variance Tradeoff
In machine learning two errors should be minimized at the same time: bias and variance.

Bias: Bias is an error caused by false assumptions in algorithm. High bias might cause underfitting.
Variance: Variance is an error stemming from sensitivity in training data. A high variance might cause overfitting. In this case noise in training data is modeled rather than the underlying relationship.
Both errors cannot be minimized at the same time, so a reasonable tradeoff is required.

# Resampling Methods

There are different resampling methods. In this post hold-out, k-fold cross validation and leave-one-out cross validation are presented.

## Holdout Method

Easiest approach is to take a certain ratio of data, e.g. say 80 % for training, and the residual 20 % for testing. Problems might be that it is not affordable to hold back a subset for validation. Also, the split might have a negative impact on the validation error.

Some methods have been developed to overcome these limitations.

## k-Fold Cross Validation (CV)

This method is a generalisation of hold-out method. Data is randomly splitted in k-folds, typically 10. Let’s assume 10 folds for now. Folds 2 to 10 are used for training the model, and the residual first fold for validation of the model. Now, the process is repeated. But this time the second fold is used for validation and folds 1, 3 to 10 are used for training the model. This process is repeated k times.

Final predictor is the average of the models.

## Leave-One-Out Cross Validation (LOOCV)

This method requires (n-1) data for training, and 1 data set for validation. This process is repeated n times. It is numerically very costly, but also is prone to overfitting.

# Data Understanding

Wine variants of Portuguese "Vinho Verde" are analysed with regards to their chemical properties. Finally, we are interested how these chemical properties influence wine quality.

These are our independent variables:

1 - fixed acidity 
2 - volatile acidity 
3 - citric acid 
4 - residual sugar 
5 - chlorides 
6 - free sulfur dioxide 
7 - total sulfur dioxide 
8 - density 
9 - pH 
10 - sulphates 
11 - alcohol 

This is our dependent variable:

12 - quality (score between 0 and 10)

## Packages

```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(keras))
suppressPackageStartupMessages(library(caret))

# own functions
source("./functions/train_val_test.R")
```


## Data Import

```{r}
# if file does not exist, download it first
file_path <- "./data/winequality-red.csv"
if (!file.exists(file_path)) {
  dir.create("./data")
  url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
  download.file(url = url, 
                destfile = file_path)
}

df <- read.csv(file_path, sep = ";")
```


# Simple Train / Validation Split

```{r}
# add code here
```

Training performance:

```{r}
# add code here
```


Validation performance:

```{r}
# add code here
```

Training and validation R**2 are quite different and depend on sampling of the data. Run this several times and you see how much the performance changes.

# Cross Validation

## 10-fold Cross Validation

```{r}
# add code here
```


```{r}
# add code here
```

Check the performance:

```{r}
# add code here
```


## Leave One Out CV

If LOOCV should be used code is only marginally changed. Parameter method in trainControl is changed to “LOOCV”.

Computational time is increased significantly.

```{r}
# add code here
```

```{r}
# add code here
```

# Acknowledgement

This dataset was provided by:

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
